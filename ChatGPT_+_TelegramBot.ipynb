{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Решение задачи"
      ],
      "metadata": {
        "id": "lSUbb0b48kDQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Скачаем необходимые библиотеки:"
      ],
      "metadata": {
        "id": "52mepp8f_H4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q aiogram\n",
        "!pip install -q openai wikipedia tiktoken mwclient mwparserfromhell\n",
        "!pip install -q nest_asyncio"
      ],
      "metadata": {
        "id": "tmwmI1gMmHhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Импортируем необходимые библиотеки:"
      ],
      "metadata": {
        "id": "Swi8dyHL_Lzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import asyncio\n",
        "import re\n",
        "import warnings\n",
        "import requests\n",
        "import numpy as np\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "import tiktoken\n",
        "import wikipedia\n",
        "import pandas as pd\n",
        "import ast\n",
        "from scipy import spatial\n",
        "import mwclient\n",
        "import mwparserfromhell\n",
        "from aiogram import Bot, Dispatcher, types\n",
        "from aiogram.filters import Command\n",
        "from google.colab import userdata\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply() #позволяет использовать asyncio.run() в средах с вложенным циклом событий"
      ],
      "metadata": {
        "id": "wk1IFUqQmIZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Отключение предупреждений:"
      ],
      "metadata": {
        "id": "cpUvK1q2_kRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "94dBhOOfmJ6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получаем ключ от **VSEGPT** и токен для Telegram-бота. Предварительно добавили их в секреты **Google Colab**. Также выполним настройку клиента **OpenAI**, заточенную под сервис, на котором приобретен ключ:"
      ],
      "metadata": {
        "id": "ZfKGij5cAGcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    openai_key = userdata.get('VSEGPT_API_K')\n",
        "    TELEGRAM_TOKEN = userdata.get('BOT_API')\n",
        "except userdata.SecretNotFoundError as e:\n",
        "    raise Exception(f\"Секрет не найден: {e}\")\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
        "client = OpenAI(\n",
        "    api_key=openai_key,\n",
        "    base_url=\"https://api.vsegpt.ru/v1\",\n",
        ")"
      ],
      "metadata": {
        "id": "285GEDH7mLhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`GPT_MODEL` = 'gpt-3.5-turbo' — используемая модель GPT для генерации ответов на вопросы;\n",
        "\n",
        "`CATEGORY_TITLE` = \"Category:Academy Awards\" — категория Википедии, из которой собираются данные (все статьи, связанные с Оскарами);\n",
        "\n",
        "`WIKI_SITE` = \"en.wikipedia.org\" — сайт Википедии (английская версия), откуда извлекается информация;\n",
        "\n",
        "`MAX_TOKENS` = 1600 — максимальное количество токенов в одном куске текста (для обработки длинных статей);\n",
        "\n",
        "`EMBEDDING_MODEL` = \"text-embedding-ada-002\" — модель для создания векторных представлений текста (для поиска релевантных ответов);\n",
        "\n",
        "`SECTIONS_TO_IGNORE` — список разделов статей Википедии, которые игнорируются, чтобы оставить только полезный контент."
      ],
      "metadata": {
        "id": "d-mgCyZVBS8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_MODEL = 'gpt-3.5-turbo'\n",
        "CATEGORY_TITLE = \"Category:Academy Awards\"\n",
        "WIKI_SITE = \"en.wikipedia.org\"\n",
        "MAX_TOKENS = 1600\n",
        "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
        "SECTIONS_TO_IGNORE = [\n",
        "    \"See also\", \"References\", \"External links\", \"Further reading\",\n",
        "    \"Footnotes\", \"Bibliography\", \"Sources\", \"Citations\",\n",
        "    \"Literature\", \"Footnotes\", \"Notes and references\", \"Photo gallery\",\n",
        "    \"Works cited\", \"Photos\", \"Gallery\", \"Notes\",\n",
        "    \"References and sources\", \"References and notes\",\n",
        "]"
      ],
      "metadata": {
        "id": "2NMzWp19mNqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Эта функция рекурсивно собирает заголовки статей из категории Википедии и её подкатегорий:"
      ],
      "metadata": {
        "id": "Rjg9uTKnFwCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def titles_from_category(\n",
        "    category: mwclient.listing.Category, #задаем типизированный параметр категории статей\n",
        "    max_depth: int #определяем глубину вложения статей\n",
        ") -> set[str]:\n",
        "    titles = set() #используем множество для хранения заголовков статей\n",
        "    for cm in category.members(): #перебираем вложенные объекты категории\n",
        "        if type(cm) == mwclient.page.Page: #если объект является страницей\n",
        "            titles.add(cm.name) #в хранилище заголовков добавляем имя страницы\n",
        "        elif isinstance(cm, mwclient.listing.Category) and max_depth > 0: #если объект является категорией и глубина вложения не достигла максимальной\n",
        "            deeper_titles = titles_from_category(cm, max_depth=max_depth - 1) #вызываем рекурсивно функцию для подкатегории\n",
        "            titles.update(deeper_titles) #добавление в множество элементов из другого множества\n",
        "    return titles"
      ],
      "metadata": {
        "id": "5dcZAa4AmSnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Следующая функция возвращает список всех вложенных секций для заданной секции страницы Википедии:"
      ],
      "metadata": {
        "id": "GBFnTX5MIS_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def all_subsections_from_section(\n",
        "    section: mwparserfromhell.wikicode.Wikicode, #текущая секция\n",
        "    parent_titles: list[str], #заголовки родителя\n",
        "    sections_to_ignore: set[str], #секции, которые необходимо проигнорировать\n",
        ") -> list[tuple[list[str], str]]:\n",
        "\n",
        "    #извлекаем заголовки текущей секции\n",
        "    headings = [str(h) for h in section.filter_headings()]\n",
        "    title = headings[0]\n",
        "    #заголовки Википедии имеют вид: \"== Heading ==\"\n",
        "    if title.strip(\"=\" + \" \") in sections_to_ignore:\n",
        "        #если заголовок секции в списке для игнора, то пропускаем его\n",
        "        return []\n",
        "\n",
        "    titles = parent_titles + [title] #объединим заголовки и подзаголовки, чтобы сохранить контекст для chatGPT\n",
        "    full_text = str(section) #преобразуем wikicode секции в строку\n",
        "    section_text = full_text.split(title)[1] #выделяем текст секции без заголовка\n",
        "    if len(headings) == 1:\n",
        "        #если один заголовок, то формируем результирующий список\n",
        "        return [(titles, section_text)]\n",
        "    else:\n",
        "        first_subtitle = headings[1]\n",
        "        section_text = section_text.split(first_subtitle)[0]\n",
        "        results = [(titles, section_text)] #формируем результирующий список из текста до первого подзаголовка\n",
        "        for subsection in section.get_sections(levels=[len(titles) + 1]):\n",
        "            results.extend(\n",
        "                #вызываем функцию получения вложенных секций для заданной секции\n",
        "                all_subsections_from_section(subsection, titles, sections_to_ignore)\n",
        "                )  #объединяем результирующие списки данной функции и вызываемой\n",
        "        return results"
      ],
      "metadata": {
        "id": "sVCi_xZmmUQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Эта функция возвращает список всех секций страницы, за исключением тех, которые отбрасываем:"
      ],
      "metadata": {
        "id": "JmLaDE8wI9Dh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def all_subsections_from_title(\n",
        "    title: str, #заголовок статьи Википедии, которую парсим\n",
        "    sections_to_ignore: set[str] = SECTIONS_TO_IGNORE, #секции, которые игнорируем\n",
        "    site_name: str = WIKI_SITE, #ссылка на сайт википедии\n",
        ") -> list[tuple[list[str], str]]:\n",
        "\n",
        "    #инициализация объекта MediaWiki\n",
        "    #WIKI_SITE ссылается на англоязычную часть Википедии\n",
        "    site = mwclient.Site(site_name)\n",
        "    page = site.pages[title] #запрашиваем страницу по заголовку\n",
        "    text = page.text() #получаем текстовое представление страницы\n",
        "    parsed_text = mwparserfromhell.parse(text) #удобный парсер для MediaWiki\n",
        "    headings = [str(h) for h in parsed_text.filter_headings()] #извлекаем заголовки\n",
        "    if headings: #если заголовки найдены\n",
        "        #в качестве резюме берем текст до первого заголовка\n",
        "        summary_text = str(parsed_text).split(headings[0])[0]\n",
        "    else:\n",
        "        #если нет заголовков, то весь текст считаем резюме\n",
        "        summary_text = str(parsed_text)\n",
        "    results = [([title], summary_text)] #добавляем резюме в результирующий список\n",
        "    for subsection in parsed_text.get_sections(levels=[2]): #извлекаем секции 2-го уровня\n",
        "        results.extend(\n",
        "            #вызываем функцию получения вложенных секций для заданной секции\n",
        "            all_subsections_from_section(subsection, [title], sections_to_ignore)\n",
        "        ) #объединяем результирующие списки данной функции и вызываемой\n",
        "    return results"
      ],
      "metadata": {
        "id": "xMi5NjfFmWYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Далее напишем функцию для очистки текста секции от ссылок <ref>xyz</ref>, начальных и конечных пробелов:"
      ],
      "metadata": {
        "id": "nLLwwd15LD1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_section(section: tuple[list[str], str]) -> tuple[list[str], str]:\n",
        "    titles, text = section\n",
        "    text = re.sub(r\"<ref.*?</ref>\", \"\", text) #удаляем ссылки\n",
        "    text = text.strip() #удаляем пробелы вначале и конце\n",
        "    return (titles, text)"
      ],
      "metadata": {
        "id": "4vpUPfBUmddZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Отфильтруем короткие и пустые секции:"
      ],
      "metadata": {
        "id": "qrkR_llDLrX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def keep_section(section: tuple[list[str], str]) -> bool:\n",
        "    _, text = section\n",
        "    return len(text) >= 16"
      ],
      "metadata": {
        "id": "9Qb3a1b1mfCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция подсчета токенов:"
      ],
      "metadata": {
        "id": "ITF6P9vAMbsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
        "    encoding = tiktoken.encoding_for_model(model)\n",
        "    return len(encoding.encode(text))"
      ],
      "metadata": {
        "id": "8fR3Uzg8miA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция разделения строк:"
      ],
      "metadata": {
        "id": "VHAYu6YCMhvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def halved_by_delimiter(string: str, delimiter: str = \"\\n\") -> list[str, str]:\n",
        "    chunks = string.split(delimiter) #делим строку на части по разделителю, по умолчанию \\n - перенос строки\n",
        "    if len(chunks) == 1:\n",
        "        return [string, \"\"]  #разделитель не найден\n",
        "    elif len(chunks) == 2:\n",
        "        return chunks  #нет необходимости искать промежуточную точку\n",
        "    else:\n",
        "        #считаем токены\n",
        "        total_tokens = num_tokens(string)\n",
        "        halfway = total_tokens // 2\n",
        "        best_diff = halfway #предварительное разделение по середине числа токенов\n",
        "        #в цикле ищем какой из разделителей, будет ближе всего к best_diff\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            left = delimiter.join(chunks[: i + 1])\n",
        "            left_tokens = num_tokens(left)\n",
        "            diff = abs(halfway - left_tokens)\n",
        "            if diff >= best_diff:\n",
        "                break\n",
        "            else:\n",
        "                best_diff = diff\n",
        "        left = delimiter.join(chunks[:i])\n",
        "        right = delimiter.join(chunks[i:])\n",
        "        #возвращаем левую и правую часть оптимально разделенной строки\n",
        "        return [left, right]"
      ],
      "metadata": {
        "id": "7rdZv1nOmjMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Затем создадим функцию, которая обрезает строку до максимально разрешенного числа токенов:"
      ],
      "metadata": {
        "id": "aqdOCUq3M2ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def truncated_string(\n",
        "    string: str, #строка\n",
        "    model: str, #модель\n",
        "    max_tokens: int, #максимальное число разрешенных токенов\n",
        "    print_warning: bool = True, #флаг вывода предупреждения\n",
        ") -> str:\n",
        "    encoding = tiktoken.encoding_for_model(model)\n",
        "    encoded_string = encoding.encode(string)\n",
        "    truncated_string = encoding.decode(encoded_string[:max_tokens]) #обрезаем строку и декодируем обратно\n",
        "    if print_warning and len(encoded_string) > max_tokens:\n",
        "        print(f\"Предупреждение: Строка обрезана с {len(encoded_string)} токенов до {max_tokens} токенов.\")\n",
        "    #усеченная строка\n",
        "    return truncated_string"
      ],
      "metadata": {
        "id": "EcIkbZPRmloC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция делит секции статьи на части по максимальному числу токенов:"
      ],
      "metadata": {
        "id": "ekNIBBclNC-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_strings_from_subsection(\n",
        "    subsection: tuple[list[str], str], #секции\n",
        "    max_tokens: int = 1000, #максимальное число токенов\n",
        "    model: str = GPT_MODEL, #модель\n",
        "    max_recursion: int = 5, #максимальное число рекурсий\n",
        ") -> list[str]:\n",
        "    titles, text = subsection\n",
        "    string = \"\\n\\n\".join(titles + [text])\n",
        "    num_tokens_in_string = num_tokens(string)\n",
        "    #если длина соответствует допустимой, то вернет строку\n",
        "    if num_tokens_in_string <= max_tokens:\n",
        "        return [string]\n",
        "    #если в результате рекурсия не удалось разделить строку, то просто усечем ее по числу токенов\n",
        "    elif max_recursion == 0:\n",
        "        return [truncated_string(string, model=model, max_tokens=max_tokens)]\n",
        "    #иначе разделим пополам и выполним рекурсию\n",
        "    else:\n",
        "        titles, text = subsection\n",
        "        for delimiter in [\"\\n\\n\", \"\\n\", \". \"]: #пробуем использовать разделители от большего к меньшему (разрыв, абзац, точка)\n",
        "            left, right = halved_by_delimiter(text, delimiter=delimiter)\n",
        "            if left == \"\" or right == \"\":\n",
        "                #если какая-либо половина пуста, повторяем попытку с более простым разделителем\n",
        "                continue\n",
        "            else:\n",
        "                #применим рекурсию на каждой половине\n",
        "                results = []\n",
        "                for half in [left, right]:\n",
        "                    half_subsection = (titles, half)\n",
        "                    half_strings = split_strings_from_subsection(\n",
        "                        half_subsection,\n",
        "                        max_tokens=max_tokens,\n",
        "                        model=model,\n",
        "                        max_recursion=max_recursion - 1, #уменьшаем максимальное число рекурсий\n",
        "                    )\n",
        "                    results.extend(half_strings)\n",
        "                return results\n",
        "    #иначе никакого разделения найдено не было, поэтому просто обрезаем строку (должно быть очень редко)\n",
        "    return [truncated_string(string, model=model, max_tokens=max_tokens)]"
      ],
      "metadata": {
        "id": "Cmx_itGEmoYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция отправки **chatGPT** строки для ее токенизации (вычисления эмбедингов):"
      ],
      "metadata": {
        "id": "ZAjLcyFxNSif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding(text, model=EMBEDDING_MODEL):\n",
        "    return client.embeddings.create(input=[text], model=model).data[0].embedding"
      ],
      "metadata": {
        "id": "ZwVmt8G0mptb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Эта функция находит самые релевантные тексты из базы знаний для заданного запроса:"
      ],
      "metadata": {
        "id": "wXcCQd_vNS5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def strings_ranked_by_relatedness(\n",
        "    query: str, #пользовательский запрос\n",
        "    df: pd.DataFrame, #DataFrame со столбцами text и embedding (база знаний)\n",
        "    relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y), # функция схожести, косинусное расстояние\n",
        "    top_n: int = 100 #выбор лучших n-результатов\n",
        ") -> tuple[list[str], list[float]]: #функция возвращает кортеж двух списков, первый содержит строки, второй - числа с плавающей запятой\n",
        "\n",
        "    #отправляем в OpenAI API пользовательский запрос для токенизации\n",
        "    query_embedding_response = openai.embeddings.create(\n",
        "        model=EMBEDDING_MODEL,\n",
        "        input=query,\n",
        "    )\n",
        "    query_embedding = query_embedding_response.data[0].embedding #получен токенизированный пользовательский запрос\n",
        "    #сравниваем пользовательский запрос с каждой токенизированной строкой DataFrame\n",
        "    strings_and_relatednesses = [\n",
        "        (row[\"text\"], relatedness_fn(query_embedding, row[\"embedding\"]))\n",
        "        for i, row in df.iterrows()\n",
        "    ]\n",
        "    strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True) #сортируем по убыванию схожести полученный список\n",
        "    strings, relatednesses = zip(*strings_and_relatednesses) #преобразовываем наш список в кортеж из списков\n",
        "    return strings[:top_n], relatednesses[:top_n] #возвращаем n лучших результатов"
      ],
      "metadata": {
        "id": "fcVNpFiHmrRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция формирования запроса к **chatGPT** по пользовательскому вопросу и базе знаний:"
      ],
      "metadata": {
        "id": "LBVrsg1aNTXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def query_message(\n",
        "    query: str, #пользовательский запрос\n",
        "    df: pd.DataFrame, #DataFrame со столбцами text и embedding (база знаний)\n",
        "    model: str, #модель\n",
        "    token_budget: int #ограничение на число отсылаемых токенов в модель\n",
        ") -> str:\n",
        "    strings, relatednesses = strings_ranked_by_relatedness(query, df) #функция ранжирования базы знаний по пользовательскому запросу\n",
        "    #шаблон инструкции для chatGPT\n",
        "    message = 'Use the below articles on the 2022 Winter Olympics to answer the subsequent question. If the answer cannot be found in the articles, write \"I could not find an answer.\"'\n",
        "    #шаблон для вопроса\n",
        "    question = f\"\\n\\nQuestion: {query}\"\n",
        "    #добавляем к сообщению для chatGPT релевантные строки из базы знаний, пока не выйдем за допустимое число токенов\n",
        "    for string in strings:\n",
        "        next_article = f'\\n\\nWikipedia article section:\\n\"\"\"\\n{string}\\n\"\"\"'\n",
        "        if (num_tokens(message + next_article + question, model=model) > token_budget):\n",
        "            break\n",
        "        else:\n",
        "            message += next_article\n",
        "    return message + question"
      ],
      "metadata": {
        "id": "JYqCbL73mtHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Финальная функция для обращения к **chatGPT**:"
      ],
      "metadata": {
        "id": "UAXQNAPxNTrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ask(\n",
        "    query: str, #пользовательский запрос\n",
        "    df: pd.DataFrame, #DataFrame со столбцами text и embedding (база знаний)\n",
        "    model: str = GPT_MODEL, #модель\n",
        "    token_budget: int = 4096 - 500, #ограничение на число отсылаемых токенов в модель\n",
        "    print_message: bool = False, #нужно ли выводить сообщение перед отправкой\n",
        ") -> str:\n",
        "\n",
        "    #формируем сообщение к chatGPT (функция выше)\n",
        "    message = query_message(query, df, model=model, token_budget=token_budget)\n",
        "    #если параметр True, то выводим сообщение\n",
        "    if print_message:\n",
        "        print(message)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You answer questions about Academy Awards.\"},\n",
        "        {\"role\": \"user\", \"content\": message},\n",
        "    ]\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0 #гиперпараметр степени случайности при генерации текста. Влияет на то, как модель выбирает следующее слово в последовательности\n",
        "    )\n",
        "    response_message = response.choices[0].message.content\n",
        "    return response_message"
      ],
      "metadata": {
        "id": "oGvtnroBmuo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализуем все наши раннее созданные функции, создадим базу знаний, которую будем использовать для работы с **chatGPT**:"
      ],
      "metadata": {
        "id": "LvutsWH-NUHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAVE_PATH = \"./academy_awards_knowledge_base.csv\" #путь к файлу, где будет сохранена/загружена база знаний\n",
        "\n",
        "#проверяем, существует ли уже сохраненная база знаний\n",
        "if os.path.exists(SAVE_PATH):\n",
        "    #если файл существует — загружаем его\n",
        "    print(f\"Загрузка базы знаний из файла: {SAVE_PATH}\")\n",
        "    df = pd.read_csv(SAVE_PATH)  #чтение CSV с помощью pandas\n",
        "    df['embedding'] = df['embedding'].apply(ast.literal_eval) #преобразуем эмбеддинги из строк в списки чисел (при сохранении они хранились как строки)\n",
        "\n",
        "    print(f\"База знаний загружена: {len(df)} записей\")\n",
        "else:\n",
        "    #если базы знаний нет — создаём новую\n",
        "    print(\"Создание базы знаний...\")\n",
        "\n",
        "    site = mwclient.Site(WIKI_SITE) #подключаемся к Википедии через библиотеку mwclient\n",
        "    category_page = site.pages[CATEGORY_TITLE] #получаем категорию \"Academy Awards\" (все статьи об Оскарах)\n",
        "    titles = titles_from_category(category_page, max_depth=1) #собираем заголовки статей из категории (max_depth=1 — только первые подкатегории)\n",
        "    print(f\"Создано {len(titles)} заголовков статей в категории {CATEGORY_TITLE}.\")\n",
        "\n",
        "    #извлекаем все секции и подсекции из статей\n",
        "    wikipedia_sections = []\n",
        "    for title in titles:\n",
        "        wikipedia_sections.extend(all_subsections_from_title(title))\n",
        "    print(f\"Найдено {len(wikipedia_sections)} секций на {len(titles)} страницах\")\n",
        "\n",
        "    wikipedia_sections = [clean_section(ws) for ws in wikipedia_sections] #очищаем секции от вики-разметки и ссылок вроде <ref>...</ref>\n",
        "\n",
        "    #фильтруем секции: оставляем только те, у которых достаточно текста (длина > 16 символов)\n",
        "    original_num_sections = len(wikipedia_sections)\n",
        "    wikipedia_sections = [ws for ws in wikipedia_sections if keep_section(ws)]\n",
        "    print(f\"Отфильтровано {original_num_sections-len(wikipedia_sections)} секций, осталось {len(wikipedia_sections)} секций.\")\n",
        "\n",
        "    #разбиваем длинные секции на части по MAX_TOKENS (1600 токенов) для обработки GPT\n",
        "    wikipedia_strings = []\n",
        "    for section in wikipedia_sections:\n",
        "        wikipedia_strings.extend(split_strings_from_subsection(section, max_tokens=MAX_TOKENS))\n",
        "    print(f\"{len(wikipedia_sections)} секций Википедии поделены на {len(wikipedia_strings)} строк.\")\n",
        "\n",
        "    #создаем DataFrame для хранения текстов и их эмбеддингов\n",
        "    print(\"Создание эмбеддингов...\")\n",
        "    df = pd.DataFrame({\"text\": wikipedia_strings[:100]})  #берём первые 100 записей для экономии времени\n",
        "\n",
        "    df['embedding'] = df.text.apply(lambda x: get_embedding(x, model=EMBEDDING_MODEL)) #генерируем эмбеддинги для каждого текста с помощью OpenAI API (model=text-embedding-ada-002)\n",
        "\n",
        "    #сохраняем базу знаний в CSV для повторного использования\n",
        "    df.to_csv(SAVE_PATH, index=False)\n",
        "    print(f\"База знаний сохранена в: {SAVE_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNFwDSaKm1KZ",
        "outputId": "f7c4501d-4c2a-4bf5-9673-1d8f2d39ee5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Загрузка базы знаний из файла: ./academy_awards_knowledge_base.csv\n",
            "База знаний загружена: 100 записей\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для информативности и ясности выведем датафрейм:"
      ],
      "metadata": {
        "id": "q8hrOraGNWjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9711
        },
        "id": "4mjvnpRr7Mrn",
        "outputId": "58193536-3575-47da-8aa5-eff438d9a694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  3rd Academy Awards\\n\\n{{Oscars short descripti...   \n",
              "1  3rd Academy Awards\\n\\n== Winners and nominees=...   \n",
              "2  3rd Academy Awards\\n\\n== Winners and nominees=...   \n",
              "3  3rd Academy Awards\\n\\n== Multiple nominations ...   \n",
              "4  Academy Awards\\n\\n{{Short description|Annual a...   \n",
              "\n",
              "                                           embedding  \n",
              "0  [-0.017022229731082916, -0.020548079162836075,...  \n",
              "1  [-0.011391614563763142, -0.007212481927126646,...  \n",
              "2  [-0.012653084471821785, -0.019328653812408447,...  \n",
              "3  [-0.015558500774204731, -0.007036137860268354,...  \n",
              "4  [-0.011331407353281975, 0.0011018485529348254,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5fc85eaf-737a-4d18-aa02-294e820e0c68\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3rd Academy Awards\\n\\n{{Oscars short descripti...</td>\n",
              "      <td>[-0.017022229731082916, -0.020548079162836075,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3rd Academy Awards\\n\\n== Winners and nominees=...</td>\n",
              "      <td>[-0.011391614563763142, -0.007212481927126646,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3rd Academy Awards\\n\\n== Winners and nominees=...</td>\n",
              "      <td>[-0.012653084471821785, -0.019328653812408447,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3rd Academy Awards\\n\\n== Multiple nominations ...</td>\n",
              "      <td>[-0.015558500774204731, -0.007036137860268354,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Academy Awards\\n\\n{{Short description|Annual a...</td>\n",
              "      <td>[-0.011331407353281975, 0.0011018485529348254,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5fc85eaf-737a-4d18-aa02-294e820e0c68')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5fc85eaf-737a-4d18-aa02-294e820e0c68 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5fc85eaf-737a-4d18-aa02-294e820e0c68');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6d7c1f70-903c-4fbd-94c0-4810bd09e86b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6d7c1f70-903c-4fbd-94c0-4810bd09e86b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6d7c1f70-903c-4fbd-94c0-4810bd09e86b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"List of superlative Academy Award winners and nominees\\n\\n== Performances of the same character ==\\n\\n{| class=\\\"wikitable\\\"\\n|-\\n! style=\\\"width:375px;\\\" | Character\\n! style=\\\"width:175px;\\\" | Actor\\n! style=\\\"width:225px;\\\" | Film\\n! style=\\\"width:025px;\\\" | Year\\n! style=\\\"width:150px;\\\" | Category\\n! style=\\\"width:050px;\\\" | Status\\n|-\\n| rowspan=\\\"2\\\" | [[Nurse (Romeo and Juliet)|Anita]]\\n| [[Rita Moreno]]\\n| ''[[West Side Story (1961 film)|West Side Story]]''\\n| 1961\\n| rowspan=\\\"2\\\" | [[Academy Award for Best Supporting Actress|Best Supporting Actress]]\\n| {{won}}\\n|-\\n| [[Ariana DeBose]]\\n| ''[[West Side Story (2021 film)|West Side Story]]''\\n| 2021\\n| {{won}}\\n|-\\n| rowspan=\\\"2\\\" | [[Billie Holiday]] <small>({{nee|Eleanora Fagan}})</small>\\n| [[Diana Ross]]\\n| ''[[Lady Sings the Blues (film)|Lady Sings the Blues]]''\\n| 1972\\n| rowspan=\\\"2\\\" | [[Academy Award for Best Actress|Best Lead Actress]]\\n| {{nom}}\\n|-\\n| [[Andra Day]]\\n| ''[[The United States vs. Billie Holiday|The United States<br>vs. Billie Holiday]]''\\n| 2020/<br>2021\\n| {{nom}}\\n|-\\n| rowspan=\\\"2\\\" | [[Cyrano de Bergerac]]\\n| [[Jos\\u00e9 Ferrer]]\\n| ''[[Cyrano de Bergerac (1950 film)|Cyrano de Bergerac]]''\\n| 1950\\n| rowspan=\\\"2\\\" | [[Academy Award for Best Actor|Best Lead Actor]]\\n| {{won}}\\n|-\\n| [[G\\u00e9rard Depardieu]]\\n| ''[[Cyrano de Bergerac (1990 film)|Cyrano de Bergerac]]''\\n| 1990\\n| {{nom}}\\n|-\\n| rowspan=\\\"2\\\" | [[Order of the British Empire|Dame]] [[Iris Murdoch]]\\n| [[Judi Dench]]\\n| rowspan=\\\"2\\\" | ''[[Iris (2001 film)|Iris]]''\\n| rowspan=\\\"2\\\" | 2001\\n| Best Lead Actress\\n| {{nom}}\\n|-\\n| [[Kate Winslet]]\\n| Best Supporting Actress\\n| {{nom}}\\n|-\\n| rowspan=\\\"2\\\" | [[Don (honorific)|Don]] [[Michael Corleone]]\\n| rowspan=\\\"2\\\" | [[Al Pacino]]\\n| ''[[The Godfather]]''\\n| 1972\\n| [[Academy Award for Best Supporting Actor|Best Supporting Actor]]\\n| {{nom}}\\n|-\\n| rowspan=\\\"2\\\" | ''[[The Godfather Part II]]''\\n| rowspan=\\\"2\\\" | 1974\\n| Best Lead Actor\\n| {{nom}}\\n|-\\n| rowspan=\\\"2\\\" | Don [[Vito Corleone]] <small>({{ne|Andolini}})</small>\\n| [[Robert De Niro]]\\n| Best Supporting Actor\\n| {{won}}\\n|-\\n| [[Marlon Brando]] '''\\u00a7'''\\n| ''The Godfather''\\n| 1972\\n| rowspan=\\\"6\\\" | Best Lead Actor\\n| {{won}}\\n|-\\n| rowspan=\\\"2\\\" | [[Eddie Parker (pool player)|Eddie \\\"Fast Eddie\\\" Felson]]\\n| rowspan=\\\"2\\\" | [[Paul Newman]]\\n| ''[[The Hustler]]''\\n| 1961\\n| {{nom}}\\n|-\\n| ''[[The Color of Money]]''\\n| 1986\\n| {{win}}\\n|-\\n| rowspan=\\\"2\\\" | [[Priesthood in the Catholic Church|Father]] Chuck O'Malley\\n| rowspan=\\\"2\\\" | [[Bing Crosby]]\\n| ''[[The Bells of St. Mary's]]''\\n| 1945\\n| {{nom}}\\n|-\\n| rowspan=\\\"3\\\" | ''[[Going My Way]]''\\n| rowspan=\\\"3\\\" | 1944\",\n          \"Academy Awards\\n\\n== Notable highest wins and nominees ==\\n\\n=== By people ===\\n\\n| Costume designer\\n|-\\n| [[Denzel Washington]]\\n| Actor and filmmaker\\n|-\\n| rowspan=\\\"13\\\" style=\\\"text-align:center\\\"| 9\\n| [[Ingmar Bergman]]\\n| Filmmaker\\n|-\\n| [[Milena Canonero]]\\n| Costume designer\\n|-\\n| [[Pete Docter]]\\n| Filmmaker, animator and voice actor\\n|-\\n| [[Jacqueline Durran]]\\n| Costume designer\\n|-\\n| [[Nancy Haigh]]\\n| Set decorator\\n|-\\n| [[Alejandro Gonz\\u00e1lez I\\u00f1\\u00e1rritu]]\\n| Filmmaker\\n|-\\n| [[Peter Jackson]]\\n| Filmmaker\\n|-\\n| [[Stanley Kramer]]\\n| Filmmaker\\n|-\\n| [[Catherine Martin (designer)|Catherine Martin]]\\n| Costume designer, production designer and producer\\n|-\\n| [[Scott Millan]]\\n| Sound mixer\\n|-\\n| [[Scott Rudin]]\\n| Producer\\n|-\\n| [[Thelma Schoonmaker]]\\n| Film editor\\n|-\\n| [[Sherman Brothers]]\\n| Composers and songwriters\\n|-\\n| rowspan=\\\"18\\\" style=\\\"text-align:center\\\"| 8\\n| [[Wes Anderson]]\\n| Filmmaker\\n|-\\n| [[Cate Blanchett]]\\n| Actress\\n|-\\n| [[Kenneth Branagh]]\\n| Actor and filmmaker\\n|-\\n| [[Marlon Brando]]\\n| Actor\\n|-\\n| [[James L. Brooks]]\\n| Filmmaker\\n|-\\n| [[George Clooney]]\\n| Actor and filmmaker\\n|-\\n| [[Glenn Close]]\\n| Actress\\n|-\\n| [[Judi Dench]]\\n| Actress\\n|-\\n| [[Dede Gardner]]\\n| Producer\\n|-\\n| [[Michael Kahn (film editor)|Michael Kahn]]\\n| Film editor\\n|-\\n| [[Kathleen Kennedy (producer)|Kathleen Kennedy]]\\n| Producer\\n|-\\n| [[Jack Lemmon]]\\n| Actor\\n|-\\n| [[Francesca Lo Schiavo]]\\n| Set decorator\\n|-\\n| [[Emmanuel Lubezki]]\\n| Cinematographer\\n|-\\n| [[Frances McDormand]]\\n| Actress and producer\\n|-\\n| [[Christopher Nolan]]\\n| Filmmaker\\n|-\\n| [[Peter O'Toole]]\\n| Actor\\n|-\\n| [[Ken Ralston]]\\n| Visual effects supervisor\\n|-\\n| rowspan=\\\"15\\\" style=\\\"text-align:center\\\"| 7\\n| [[Howard Ashman]]\\n| Lyricist\\n|-\\n| [[Ingrid Bergman]]\\n| Actress\\n|-\\n| [[Dennis Gassner]]\\n| Production designer\\n|-\\n| [[Jeff Bridges]]\\n| Actor\\n|-\\n| [[Richard Burton]]\\n| Actor\\n|-\\n| [[James Cameron]]\\n| Filmmaker\\n|-\\n| [[Leonardo DiCaprio]]\\n| Actor and producer\\n|-\\n| [[Jane Fonda]]\\n| Actress\\n|-\\n| [[Jeremy Kleiner]]\\n| Producer\\n|-\\n| [[Martin McDonagh]]\\n| Filmmaker\\n|-\\n| [[Brad Pitt]]\\n| Actor and producer\\n|-\\n| [[Sydney Pollack]]\\n| Filmmaker\\n|-\\n| [[Mary Wills (costume designer)|Mary Wills]]\\n| Costume designer\\n|-\\n| [[Kate Winslet]]\\n| Actress\\n|-\\n| [[Albert Wolsky]]\\n| Costume designer\\n|-\\n| rowspan=\\\"17\\\" style=\\\"text-align:center\\\"| 6\\n| [[Amy Adams]]\\n| Actress\\n|-\\n| [[John Bright (costume designer)|John Bright]]\\n| Costume designer\\n|-\\n| [[Alexandra Byrne]]\\n| Costume designer\\n|-\\n| [[Ellen Burstyn]]\\n| Actress\\n|-\\n| [[Daniel Day-Lewis]]\\n| Actor\\n|-\\n| [[Guillermo del Toro]]\\n| Filmmaker\\n|-\\n| [[Eric Fellner]]\\n| Producer\\n|-\\n| [[Margaret Furse]]\\n| Costume designer\\n|-\\n| [[Tom Hanks]]\\n| Actor\\n|-\\n| [[Yorgos Lanthimos]]\\n| Filmmaker\\n|-\\n| [[Ennio Morricone]]\\n| Composer\\n|-\\n| [[Patricia Norris]]\\n| Costume designer\\n|-\\n| [[Nick Park]]\\n| Animator\\n|-\\n| [[Maggie Smith]]\\n| Actress\\n|-\\n| [[Andrew Stanton]]\\n| Animator and filmmaker\\n|-\\n| [[Gile Steele]]\\n| Costume designer\\n|-\\n| [[Richard Taylor (filmmaker)|Richard Taylor]]\\n| Costume designer, special make-up effects artist and visual effects artist\\n|-\\n| rowspan=\\\"20\\\" style=\\\"text-align:center\\\"| 5\\n| [[Tim Bevan]]\\n| Producer\\n|-\\n| [[Brad Bird]]\\n| Animator and filmmaker\\n|-\\n| [[Danilo Donati]]\\n| Costume designer and production designer\\n|-\\n| [[Todd Field]]\\n| Filmmaker\\n|-\\n| [[Alfred Hitchcock]]\\n| Filmmaker\\n|-\\n| [[Nicole Kidman]]\\n| Actress\\n|-\\n| [[Frank Marshall (filmmaker)|Frank Marshall]]\\n| Producer\\n|-\\n| [[Vittorio Nino Novarese]]\\n| Costume designer\\n|-\\n| [[Gregory Peck]]\\n| Actor\\n|-\\n| [[Sean Penn]]\\n| Actor\\n|-\\n| [[Reni\\u00e9]]\\n| Costume designer\\n|-\\n| [[Ann Roth]]\\n| Costume designer\\n|-\\n| [[David O. Russell]]\\n| Filmmaker\\n|-\\n| [[Susan Sarandon]]\\n| Actress\\n|-\\n| [[Howard Shoup]]\\n| Costume designer\\n|-\\n| [[Emma Stone]]\\n| Actress and producer\\n|-\\n| [[Barbra Streisand]]\\n| Actress, songwriter and producer\\n|-\\n| [[Piero Tosi]]\\n| Costume designer\\n|-\\n| [[Jacqueline West]]\\n| Costume designer\\n|-\\n| [[Michelle Williams (actress)|Michelle Williams]]\\n| Actress\\n|}\",\n          \"17th Academy Awards\\n\\n== Presenters and performers ==\\n\\n===Presenters===\\n\\n''(in order of appearance)''\\n\\n*[[Walter Wanger]] (Presenter: Academy Honorary Award to Bob Hope)\\n*[[Bob Hope]] (Presenter: Best Art Direction (Black-and-White), Best Art Direction (Color), Best Cinematography (Black-and-White), Best Cinematography (Color), Best Documentary Feature, Best Documentary Short Subject, Best Film Editing, Best Live Action Short Subject (One-Reel), Best Scoring of a Musical Picture, Best Scoring of a Dramatic or Comedy Picture, Best Song, Best Sound Recording, Best Special Effects, and the Scientific & Technical Awards)\\n*[[Hugo Butler]] (Presenter: Best Screenplay, Best Original Screenplay, and Best Original Motion Picture Story)\\n*[[Mervyn LeRoy]] (Presenter: Best Director)\\n*[[Hal B. Wallis]] (Presenter: Best Picture)\\n*[[Norma Shearer]] (Presenter: Irving G. Thalberg Memorial Award)\\n*[[Bob Hope]] (Presenter: Academy Juvenile Award)\\n*[[Charles Coburn]] (Presenter: Best Supporting Actor)\\n*[[Teresa Wright]] (Presenter: Best Supporting Actress)\\n*[[Gary Cooper]] (Presenter: Best Actor)\\n*[[Jennifer Jones]] (Presenter: Best Actress)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embedding\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Этот код реализует **Telegram-бота,** который отвечает на вопросы об Оскарах (Academy Awards), используя предварительно созданную базу знаний с эмбеддингами, асинхронную обработку сообщений и интеграцию с моделью **GPT** для генерации ответов:"
      ],
      "metadata": {
        "id": "b10J1lZINbTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bot = Bot(token=TELEGRAM_TOKEN)\n",
        "dp = Dispatcher()\n",
        "\n",
        "#информация о базе знаний\n",
        "KNOWLEDGE_BASE_INFO = {\n",
        "    \"тематика\": \"Academy Awards (Оскары)\",\n",
        "    \"число записей\": len(df),\n",
        "    \"пример запроса\": \"Tell me about 3rd Academy Awards\"\n",
        "}\n",
        "\n",
        "@dp.message(Command(\"start\", \"help\"))\n",
        "async def help_command(message: types.Message):\n",
        "    help_text = (\n",
        "        \"🎬 Бот для вопросов об Academy Awards (Оскарах)\\n\"\n",
        "        \"ℹ️ Информация о базе знаний:\\n\"\n",
        "        f\"- Тематика: {KNOWLEDGE_BASE_INFO['тематика']}\\n\"\n",
        "        f\"- Число записей: {KNOWLEDGE_BASE_INFO['число записей']}\\n\"\n",
        "        f\"- Пример запроса: {KNOWLEDGE_BASE_INFO['пример запроса']}\\n\\n\"\n",
        "        \"Просто задайте вопрос об Оскарах, и я постараюсь найти ответ в базе знаний!\"\n",
        "    )\n",
        "    await message.answer(help_text)\n",
        "\n",
        "@dp.message()\n",
        "async def handle_query(message: types.Message):\n",
        "    user_query = message.text.strip()\n",
        "\n",
        "    if not user_query:\n",
        "        await message.answer(\"Пожалуйста, введите ваш вопрос.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        await bot.send_chat_action(message.chat.id, \"typing\") #показываем индикатор набора текста\n",
        "\n",
        "        #используем функцию ask для получения ответа\n",
        "        response = ask(user_query, df=df)\n",
        "        await message.answer(response)\n",
        "    except Exception as e:\n",
        "        error_msg = f\"⚠️ Ошибка при обработке запроса: {str(e)}\"\n",
        "        #обрезаем сообщение об ошибке, если оно слишком длинное\n",
        "        await message.answer(error_msg[:4000])\n",
        "\n",
        "\n",
        "async def main():\n",
        "    print(f\"Бот запущен с токеном: {TELEGRAM_TOKEN[:5]}...{TELEGRAM_TOKEN[-5:]}\")\n",
        "    print(f\"Размер базы знаний: {len(df)} записей\")\n",
        "    print(\"Ожидание сообщений...\")\n",
        "    await dp.start_polling(bot)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        loop = asyncio.get_event_loop()\n",
        "        loop.run_until_complete(main())\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nБот остановлен\")\n",
        "    except Exception as e:\n",
        "        print(f\"Критическая ошибка: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sO7Flo7oZ5ZE",
        "outputId": "3f97f949-3212-4f02-f9f3-d127e78da26d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Бот запущен с токеном: 79835...SjPlM\n",
            "Размер базы знаний: 100 записей\n",
            "Ожидание сообщений...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:aiogram.dispatcher:Received SIGINT signal\n"
          ]
        }
      ]
    }
  ]
}